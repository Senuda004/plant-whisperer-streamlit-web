import base64
from io import BytesIO
import requests
from PIL import Image
import streamlit as st

# ================== CONFIG ==================
# Default API endpoint for plant prediction model
API_URL_DEFAULT = "http://13.62.8.232:5000/predict"
# Maximum allowed image size to prevent excessive payload
MAX_IMAGE_MB = 8


# ================== HELPERS ==================
def pil_to_base64_jpg(pil_img: Image.Image, quality: int = 92) -> str:
    """Encode PIL image to base64 (JPEG) to keep payload smaller."""
    buf = BytesIO()
    pil_img.save(buf, format="JPEG", quality=quality, optimize=True)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


def base64_to_pil_png(b64_str: str) -> Image.Image:
    """Decode base64 PNG -> PIL Image."""
    data = base64.b64decode(b64_str)
    return Image.open(BytesIO(data)).convert("RGB")


def call_api(api_url: str, image_b64: str, include_gradcam: bool = True, timeout: int = 45) -> dict:
    """Send base64 image to prediction API and handle response."""
    payload = {"image": image_b64, "include_gradcam": include_gradcam}
    r = requests.post(api_url, json=payload, timeout=timeout)
    # If Flask returns JSON error body, show it nicely:
    try:
        data = r.json()
    except Exception:
        r.raise_for_status()
        raise RuntimeError("API returned non-JSON response.")
    if r.status_code != 200:
        msg = data.get("error", "Request failed")
        details = data.get("details", "")
        raise RuntimeError(f"{msg}\n{details}")
    return data


# ================== PAGE SETUP ==================
st.set_page_config(
    page_title="Plant Whisperer",
    page_icon="ðŸŒ¿",
    layout="wide"
)

# Custom CSS for card-based UI design
st.markdown(
    """
    <style>
      .pw-card {
        background: rgba(255,255,255,0.04);
        border: 1px solid rgba(255,255,255,0.08);
        border-radius: 16px;
        padding: 16px 18px;
      }
      .pw-badge {
        display:inline-block;
        padding: 6px 10px;
        border-radius: 999px;
        border: 1px solid rgba(255,255,255,0.12);
        background: rgba(255,255,255,0.06);
        font-size: 12px;
      }
      .pw-title {
        font-size: 34px;
        font-weight: 800;
        line-height: 1.1;
      }
      .pw-subtitle { opacity: 0.85; }
      .pw-mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
    </style>
    """,
    unsafe_allow_html=True
)

# ================== HEADER ==================
# Two-column header: title/subtitle on left, Grad-CAM toggle on right
left, right = st.columns([0.72, 0.28], vertical_alignment="center")

with left:
    st.markdown('<div class="pw-title">ðŸŒ¿ Plant Whisperer</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="pw-subtitle">Upload a plant image â†’ get prediction, confidence, and Grad-CAM explainability.</div>',
        unsafe_allow_html=True
    )

with right:
    st.markdown('<div class="pw-card">', unsafe_allow_html=True)
    #st.markdown("**API endpoint**")
    #api_url = st.text_input(" ", value=API_URL_DEFAULT, label_visibility="collapsed")
    include_gradcam = st.toggle("Include Grad-CAM overlay", value=True)
    st.markdown('</div>', unsafe_allow_html=True)

st.divider()

# ================== MAIN LAYOUT ==================
# Left column: image upload and controls; Right column: results display
colA, colB = st.columns([0.42, 0.58], gap="large")

with colA:
    # Upload controls card
    st.markdown('<div class="pw-card">', unsafe_allow_html=True)
    st.markdown("### Upload")
    uploaded = st.file_uploader(
        "Choose an image (JPG/PNG)",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=False
    )

    st.caption(f"Tip: keep images under ~{MAX_IMAGE_MB}MB. The app compresses to JPEG before sending.")

    predict_btn = st.button("ðŸ”® Predict", type="primary", use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown("")

    st.markdown('<div class="pw-card">', unsafe_allow_html=True)
    st.markdown("### Notes")
    st.write("â€¢ Grad-CAM is generated by EC2 model API.")
    st.write("â€¢ Scores shown are the raw softmax outputs returned by the API.")
    st.markdown('</div>', unsafe_allow_html=True)

with colB:
    # Results display card
    st.markdown('<div class="pw-card">', unsafe_allow_html=True)
    st.markdown("### Results")

    if uploaded is None:
        st.info("Upload an image and click **Predict**.")
        st.markdown('</div>', unsafe_allow_html=True)
    else:
        # Validate and load the uploaded image
        try:
            pil = Image.open(uploaded).convert("RGB")
        except Exception:
            st.error("Could not read that file as an image.")
            st.markdown('</div>', unsafe_allow_html=True)
            st.stop()

        # Show previews (original)
        preview_left, preview_right = st.columns([0.48, 0.52], gap="large")
        with preview_left:
            st.markdown("**Original**")
            st.image(pil, use_container_width=True)

        # Store prediction results in session state to persist between reruns
        if "last_result" not in st.session_state:
            st.session_state.last_result = None

        if predict_btn:
            # Validate image file size before processing
            uploaded.seek(0, 2)  # move to end
            size_bytes = uploaded.tell()
            uploaded.seek(0)
            size_mb = size_bytes / (1024 * 1024)

            if size_mb > MAX_IMAGE_MB:
                st.error(f"Image is {size_mb:.1f}MB. Please upload a smaller image.")
                st.markdown('</div>', unsafe_allow_html=True)
                st.stop()

            # Compress image to reduce API payload size
            resized = pil.copy()
            resized.thumbnail((1024, 1024))

            image_b64 = pil_to_base64_jpg(resized, quality=92)

            # Send request to model API and handle errors
            with st.spinner("Calling model APIâ€¦"):
                try:
                    result = call_api(api_url, image_b64, include_gradcam=include_gradcam, timeout=60)
                    st.session_state.last_result = result
                except Exception as e:
                    st.error(str(e))
                    st.markdown('</div>', unsafe_allow_html=True)
                    st.stop()

        result = st.session_state.last_result

        if result is None:
            st.warning("Click **Predict** to run inference.")
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            # Extract prediction data from API response
            pred = result.get("prediction", "â€”")
            conf = result.get("confidence", None)
            scores = result.get("all_scores", {}) or {}
            grad_b64 = result.get("gradcam_png_base64")

            # Display prediction summary in three columns
            s1, s2, s3 = st.columns([0.34, 0.33, 0.33])
            with s1:
                st.markdown("**Prediction**")
                st.markdown(f'<span class="pw-badge">{pred}</span>', unsafe_allow_html=True)
            with s2:
                st.markdown("**Confidence**")
                if conf is None:
                    st.markdown('<span class="pw-badge">â€”</span>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<span class="pw-badge">{float(conf):.4f}</span>', unsafe_allow_html=True)
            with s3:
                st.markdown("**Classes**")
                st.markdown(f'<span class="pw-badge">{len(scores) if scores else 0}</span>', unsafe_allow_html=True)

            st.markdown("")

            # Display Grad-CAM heatmap overlay if available
            with preview_right:
                st.markdown("**Grad-CAM overlay**" if include_gradcam else "**Grad-CAM disabled**")
                if include_gradcam and grad_b64:
                    overlay_img = base64_to_pil_png(grad_b64)
                    st.image(overlay_img, use_container_width=True)
                else:
                    st.info("Grad-CAM not included in response.")

            st.markdown("---")

            # Display all class probabilities as bar chart
            if scores:
                st.markdown("#### Class scores")
                # Streamlit can chart a dict directly
                st.bar_chart(scores)

                with st.expander("Raw JSON response"):
                    st.json(result)
            else:
                st.info("No class scores returned.")

            st.markdown('</div>', unsafe_allow_html=True)

st.caption("Built with Streamlit â€¢ Backend inference served from EC2 Flask API")
